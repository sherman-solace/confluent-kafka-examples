# A local Kafka deployment to support the microservices-orders example
#
# Loads .env -> ../utils/config.env
# Run ./local-env.sh to set environment vars

version: '3.0'
services:


  # https://hub.docker.com/r/confluentinc/cp-zookeeper/tags
  zookeeper:
    image: ${REPOSITORY}/cp-zookeeper:${CONFLUENT_DOCKER_TAG}
    container_name: zookeeper
    hostname: zookeeper
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  # https://hub.docker.com/r/confluentinc/cp-kafka/tags
  kafka:
    image: ${REPOSITORY}/cp-kafka:${CONFLUENT_DOCKER_TAG}
    container_name: kafka
    hostname: kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: "INTERNAL://kafka:19092, EXTERNAL://:9092"
      # , CONTROLLER://kafka:29092"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:19092, EXTERNAL://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT, EXTERNAL:PLAINTEXT"
      # CONTROLLER:PLAINTEXT,
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
#      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
#      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka0:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka -Dcom.sun.management.jmxremote.rmi.port=9997
      # KAFKA_PROCESS_ROLES: 'broker'
      # ,controller'
      KAFKA_NODE_ID: 1
#      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
#      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29092'


  schema-registry:
    image: ${REPOSITORY}/cp-schema-registry:${CONFLUENT_DOCKER_TAG}
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      # SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: "zookeeper:2181"
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "PLAINTEXT://kafka:19092"

  ksqldb-server:
    image:  ${REPOSITORY}/ksqldb-server:0.28.2
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:19092
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_CUB_KAFKA_TIMEOUT: 120
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_CONNECT_URL: http://connect:8083
      KSQL_KSQL_SERVICE_ID: ksql_cluster
      KSQL_KSQL_HIDDEN_TOPICS: '^_.*'
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0

#  connect:
#    image: ${REPOSITORY}/cp-server-connect:${CONFLUENT_DOCKER_TAG}
#    container_name: connect
#    depends_on:
#      - kafka
#      - schema-registry
#    ports:
#      - "8083:8083"
#    environment:
#      CONNECT_BOOTSTRAP_SERVERS: kafka:19092
#      CONNECT_REST_ADVERTISED_HOST_NAME: connect
#      CONNECT_GROUP_ID: "examples-microservices-orders"
#      CONNECT_REST_ADVERTISED_HOST_NAME: connect
#
#      #      CONNECT_SECURITY_PROTOCOL: SASL_SSL
#      #      CONNECT_SASL_JAAS_CONFIG: $SASL_JAAS_CONFIG
#      #      CONNECT_SASL_MECHANISM: PLAIN
#
#      CONNECT_CONFIG_STORAGE_TOPIC: connect-demo-configs
#      CONNECT_OFFSET_STORAGE_TOPIC: connect-demo-offsets
#      CONNECT_STATUS_STORAGE_TOPIC: connect-demo-statuses
#
#      CONNECT_REPLICATION_FACTOR: 1
#      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
#      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
#      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
#
#      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
#      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
#      #      CONNECT_KEY_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: $BASIC_AUTH_CREDENTIALS_SOURCE
#      #      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: $SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
#      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
#      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
#      #      CONNECT_VALUE_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: $BASIC_AUTH_CREDENTIALS_SOURCE
#      #      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: $SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
#
#      # CLASSPATH required due to CC-2422
#      CLASSPATH: "/usr/share/java/monitoring-interceptors/monitoring-interceptors-${CONFLUENT}.jar"
#      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components/,/connectors/'
#
#      #      CONNECT_PRODUCER_SECURITY_PROTOCOL: SASL_SSL
#      #      CONNECT_PRODUCER_SASL_JAAS_CONFIG: $SASL_JAAS_CONFIG
#      #      CONNECT_PRODUCER_SASL_MECHANISM: PLAIN
#      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
#      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: $BOOTSTRAP_SERVERS
#      #      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL: SASL_SSL
#      #      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG: $SASL_JAAS_CONFIG
#      #      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM: PLAIN
#
#      #      CONNECT_CONSUMER_SECURITY_PROTOCOL: SASL_SSL
#      #      CONNECT_CONSUMER_SASL_JAAS_CONFIG: $SASL_JAAS_CONFIG
#      #      CONNECT_CONSUMER_SASL_MECHANISM: PLAIN
#      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
#      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: $BOOTSTRAP_SERVERS
#    #      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM: PLAIN
#    volumes:
#      - database:/opt/docker/db/data
#      - $PWD/stack-configs:/opt/docker/stack-configs
#    command:
#      - bash
#      - -c
#      - |
#        echo "Installing connector plugins"
#        confluent-hub install --no-prompt $REPOSITORY/kafka-connect-jdbc:$KAFKA_CONNECT_JDBC_VERSION
#        confluent-hub install --no-prompt  $REPOSITORY/kafka-connect-elasticsearch:$KAFKA_CONNECT_ES_VERSION
#        echo "Launching Kafka Connect worker"
#        /etc/confluent/docker/run
#
#  kafka-ui:
#    container_name: kafka-ui
#    image: provectuslabs/kafka-ui:latest
#    ports:
#      - 8080:8080
#    depends_on:
#      - kafka
#      - schema-registry
#      - connect
#    environment:
#      KAFKA_CLUSTERS_0_NAME: local
#      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:19092
#      KAFKA_CLUSTERS_0_METRICS_PORT: 9997
#      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
#      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
#      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://connect:8083